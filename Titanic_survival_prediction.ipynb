{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import pandas as pd",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "data = pd.read_csv(\"train.csv\")\ntest = pd.read_csv(\"test.csv\")\ntest_ids = test[\"PassengerId\"]\n\n# drop the data irrelevent for prediction\ndef clean_data(data):\n    data = data.drop([\"Ticket\",\"Cabin\",\"Name\",\"PassengerId\"] , axis=1)\n    columns = [\"SibSp\",\"Parch\",\"Fare\",\"Age\"]\n# fill in the missing value with median value   \n    for col in columns:\n        data[col].fillna(data[col].median(), inplace = True)\n        \n    data.Embarked.fillna(\"U\",inplace = True)\n    return data \n\ndata = clean_data(data)\ntest = clean_data(test)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "\ndata.head(5)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# converting values in \"sex \" and \"Embarket column\" from  \"string \" to \"int \"\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\n\ncols = [\"Sex\" , \"Embarked\"]\nfor col in cols:\n    #this will do mapping for us\n    data[col] = le.fit_transform(data[col])\n    test[col] = le.transform(test[col])\n    print(le.classes_)\n\ndata.head(5)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\n# we need x and y value for traning our model\n\ny = data[\"Survived\"]\n#droping y values\nX = data.drop(\"Survived\" , axis=1)\n#now we will split the data for training and testing model\nX_train,X_val , y_train ,y_val = train_test_split(X,y,test_size =0.2 ,random_state=42)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# now training the logistic regression model\nclf = LogisticRegression(random_state=0, max_iter=1000).fit(X_train , y_train)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# get the accuracy  through accuracy _\npredictions = clf.predict(X_val)\nfrom sklearn.metrics import accuracy_score\naccuracy_score(y_val ,predictions)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "submission_perds = clf.predict(test)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df = pd.DataFrame({\"PassengerId\":test_ids.values ,\n                  \"Survived\" : submission_perds})",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df.to_csv(\"submission.csv\" ,index =False)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}